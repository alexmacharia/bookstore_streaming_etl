{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0b31af6-88e0-4b71-a03a-644161ad530c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%run ./01-config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0399fa2b-b044-490f-bef1-d70d42afdf15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Upserter:\n",
    "    def __init__(self, merge_query, temp_view):\n",
    "        self.merge_query = merge_query\n",
    "        self.temp_view = temp_view\n",
    "\n",
    "    def upsert(self, df_micro_batch, batch_id):\n",
    "        df_micro_batch.createOrReplaceTempView(self.temp_view)\n",
    "        df_microbatch.sparkSession.sql(self.merge_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abcd0bd4-e624-420f-964c-79889f533d64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "class CDCUpserter:\n",
    "    def __init__(self, merge_query, temp_view, id_col, sort_col):\n",
    "        self.merge_query = merge_query\n",
    "        self.temp_view = temp_view\n",
    "        self.id_col = id_col\n",
    "        self.sort_col = sort_col\n",
    "\n",
    "    def upsert(self, df_micro_batch, batch_id):\n",
    "        window = Window.partition_by(self.id_col).orderBy(F.col(self.sort_col).desc())\n",
    "\n",
    "        df_micro_batch.filter(F.col(\"row_status\").isin([\"insert\", \"update\"])) \\\n",
    "            .withColumn(\"rank\", F.rank().over(window)) \\\n",
    "            .filter(\"rank == 1\") \\\n",
    "            .drop(\"rank\") \\\n",
    "            .createOrReplaceTempView(self.temp_view)\n",
    "\n",
    "        df_micro_batch.sparkSession.sql(self.merge_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "993e8ed3-7a97-4973-8cf6-458e78e09890",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04-silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
