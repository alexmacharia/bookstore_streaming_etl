{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3b8c87a-52ee-401c-b825-2cec5f378060",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./01-config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5691a55-0681-4537-9620-adb0922c09d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class SetupHandler:\n",
    "    def __init__(self, env):\n",
    "        Conf = Config()\n",
    "        self.landing_dir = Conf.base_data_dir + \"/raw\"\n",
    "        self.checkpoint_dir = Conf.base_checkpoint_dir + \"/checkpoints\"\n",
    "        self.catalog = env\n",
    "        self.db_name = Conf.db_name\n",
    "        self.initailized = False\n",
    "\n",
    "    def create_db(self):\n",
    "        #spark.catalog.clearCache()\n",
    "        print(f\"Creating database {self.catalog}.{self.db_name}\")\n",
    "        spark.sql(f\"CREATE DATABASE IF NOT EXISTS {self.catalog}.{self.db_name}\")\n",
    "        spark.sql(f\"USE {self.catalog}.{self.db_name}\")\n",
    "        self.initialized = True\n",
    "        print(\"Done\")\n",
    "\n",
    "    def create_bronze_tbl(self):\n",
    "        if self.initialized:\n",
    "            print(f\"Creating kafka multiplex bronze table\")\n",
    "            spark.sql(f\"\"\"CREATE TABLE IF NOT EXISTS {self.catalog}.{self.db_name}.bronze(\n",
    "                key string, \n",
    "                value string, \n",
    "                topic string, \n",
    "                partition long, \n",
    "                offset long, \n",
    "                timestamp timestamp,                  \n",
    "                year_month string,                  \n",
    "                load_time timestamp,\n",
    "                source_file string)\n",
    "                PARTITIONED BY (topic, year_month)\n",
    "                \"\"\")\n",
    "            print(\"Done\")\n",
    "        else:\n",
    "            raise ReferenceError(\"Database not initialized. Cannot create table in default database.\")\n",
    "\n",
    "    def create_silver_customers_tbl(self):\n",
    "        if self.initialized:\n",
    "            print(f\"Creating silver customers table\")\n",
    "            spark.sql(f\"\"\"CREATE TABLE IF NOT EXISTS {self.catalog}.{self.db_name}.silver_customers(\n",
    "                customer_id STRING,\n",
    "                email STRING,\n",
    "                first_name STRING,\n",
    "                last_name STRING,\n",
    "                gender STRING,\n",
    "                street STRING,\n",
    "                city STRING,\n",
    "                country_code STRING,\n",
    "                row_status STRING,\n",
    "                row_time timestamp)\n",
    "                \"\"\")\n",
    "            spark.sql(f\"ALTER TABLE {self.catalog}.{self.db_name}.silver_customers SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\")\n",
    "            print(\"Done\")\n",
    "        else:\n",
    "            raise ReferenceError(\"Database not initialized. Cannot create table in default database.\")\n",
    "\n",
    "    def create_silver_orders_tbl(self):\n",
    "        if self.initialized:\n",
    "            print(f\"Creating silver orders table\")\n",
    "            spark.sql(f\"\"\"CREATE TABLE IF NOT EXISTS {self.catalog}.{self.db_name}.silver_orders(\n",
    "                order_id STRING,\n",
    "                order_timestamp Timestamp,\n",
    "                customer_id STRING,\n",
    "                quantity BIGINT,\n",
    "                total BIGINT,\n",
    "                books ARRAY<STRUCT<book_id STRING, quantity BIGINT, subtotal BIGINT>>)\n",
    "                \"\"\")\n",
    "            print(\"Done\")\n",
    "        else:\n",
    "            raise ReferenceError(\"Database not initialized. Cannot create table in default database.\")\n",
    "\n",
    "    def create_silver_books_tbl(self):\n",
    "        if self.initialized:\n",
    "            print(f\"Creating silver books table\")\n",
    "            spark.sql(f\"\"\"CREATE TABLE IF NOT EXISTS {self.catalog}.{self.db_name}.silver_books(\n",
    "                book_id STRING,\n",
    "                title STRING,\n",
    "                author STRING,\n",
    "                price DOUBLE,\n",
    "                current BOOLEAN,\n",
    "                effective_date TIMESTAMP,\n",
    "                end_date TIMESTAMP)\n",
    "                \"\"\")\n",
    "            print(\"Done\")\n",
    "        else:\n",
    "            raise ReferenceError(\"Database not initialized. Cannot create table in default database.\")\n",
    "\n",
    "    def create_customers_orders_tbl(self):\n",
    "        if self.initialized:\n",
    "            print(f\"Creating customers orders table\")\n",
    "            spark.sql(f\"\"\"CREATE TABLE IF NOT EXISTS {self.catalog}.{self.db_name}.silver_customers_orders(\n",
    "                order_id STRING,\n",
    "                order_timestamp Timestamp,\n",
    "                customer_id STRING,\n",
    "                quantity BIGINT,\n",
    "                total BIGINT,\n",
    "                books ARRAY<STRUCT<book_id STRING, quantity BIGINT, subtotal BIGINT>>,\n",
    "                email STRING,\n",
    "                first_name STRING,\n",
    "                last_name STRING,\n",
    "                gender STRING,\n",
    "                street STRING,\n",
    "                city STRING,\n",
    "                country STRING,\n",
    "                row_time TIMESTAMP,\n",
    "                processed_timestamp TIMESTAMP)\n",
    "                \"\"\")\n",
    "            print(\"Done\")\n",
    "        else:\n",
    "            raise ReferenceError(\"Database not initialized. Cannot create table in default database.\")\n",
    "\n",
    "    def create_books_sales_tbl(self):\n",
    "        if self.initialized:\n",
    "            print(f\"Creating books sales table\")\n",
    "            spark.sql(f\"\"\"CREATE TABLE IF NOT EXISTS {self.catalog}.{self.db_name}.silver_books_sales(\n",
    "                order_id STRING,\n",
    "                order_timestamp Timestamp,\n",
    "                customer_id STRING,\n",
    "                quantity BIGINT,\n",
    "                total BIGINT,\n",
    "                books ARRAY<STRUCT<book_id STRING, quantity BIGINT, subtotal BIGINT>>,\n",
    "                book STRUCT<book_id STRING, quantity BIGINT, subtotal BIGINT>,\n",
    "                book_id STRING,\n",
    "                title STRING,\n",
    "                author STRING,\n",
    "                price DOUBLE,\n",
    "                current BOOLEAN,\n",
    "                effective_date TIMESTAMP,\n",
    "                end_date TIMESTAMP)\n",
    "                \"\"\")\n",
    "            print(\"Donr\")\n",
    "        else:\n",
    "            raise ReferenceError(\"Database not initialized. Cannot create table in default database.\")\n",
    "\n",
    "    \n",
    "    def create_current_books_view(self):\n",
    "        if self.initialized:\n",
    "            print(f\"Creating current books view\")\n",
    "            spark.sql(f\"\"\"CREATE OR REPLACE VIEW {self.catalog}.{self.db_name}.current_books AS\n",
    "                      SELECT book_id, title, author, price FROM {self.catalog}.{self.db_name}.silver_books WHERE current = true\"\"\")\n",
    "            print(\"Done\")\n",
    "        else:\n",
    "            raise ReferenceError(\"Database not initialized. Cannot create view in default database\")\n",
    "\n",
    "    def setup(self):\n",
    "        print(f\"Setting up database {self.catalog}.{self.db_name}\")\n",
    "        self.create_db()\n",
    "        self.create_bronze_tbl()\n",
    "        self.create_silver_customers_tbl()\n",
    "        self.create_silver_orders_tbl()\n",
    "        self.create_silver_books_tbl()\n",
    "        self.create_customers_orders_tbl()\n",
    "        self.create_books_sales_tbl()\n",
    "        self.create_current_books_view()\n",
    "        print(f\"Setup completed for database {self.catalog}.{self.db_name}\")\n",
    "\n",
    "    \n",
    "    def cleanup(self):\n",
    "        if spark.sql(f\"SHOW DATABASES IN {self.catalog}\").filter(f\"databaseName = '{self.db_name}'\").count()==1:\n",
    "            print(f\"Dropping database {self.catalog}.{self.db_name}\")\n",
    "            spark.sql(f\"DROP DATABASE IF EXISTS {self.catalog}.{self.db_name} CASCADE\")\n",
    "            print(f\"Database {self.catalog}.{self.db_name} dropped\")\n",
    "        else:\n",
    "            print(f\"Database {self.catalog}.{self.db_name} does not exist\")\n",
    "        dbutils.fs.rm(self.landing_dir, True)\n",
    "        dbutils.fs.rm(self.checkpoint_dir, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad8d2d86-1054-4cea-8a6e-5939a13020d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02-setup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
